# Hi ğŸ‘‹, Iâ€™m Maxwel Ayal Asher

###  Data Engineering enthusiast | Computer Science Student

Iâ€™m an aspiring **Data Engineer** with hands-on experience building **batch and real-time data pipelines** using Python, SQL, Apache Airflow, Kafka, and Flink frm my learning and projects. I enjoy working on data ingestion, transformation, orchestration, and turning raw data into reliable, analytics-ready systems.

---

## ğŸ§‘â€ğŸ’» What I Do
- Build **ETL / ELT pipelines** for batch and streaming data  
- Work with **Apache Kafka, Flink, Airflow**, and **PySpark**  
- Design and query **relational and time-series databases**  
- Deploy and containerize data workflows using **Docker**  
- Create **real-time and analytical dashboards** with Grafana  

---

## ğŸ”§ Tech Stack

**Programming & Querying:**  
Python, SQL  

**Data Engineering & Streaming:**  
Apache Kafka, Apache Flink, PySpark,pandas , numpy  

**Databases & Storage:**  
PostgreSQL, MySQL, Snowflake, TimescaleDB, Azure Data Lake Storage  

**Workflow Orchestration:**  
Apache Airflow  

**Cloud & DevOps:**  
AWS, Azure, Docker, Linux  

**Visualization & Monitoring:**  
Grafana
prometheus

**Version Control:**  
Git, GitHub  

---

## ğŸ“Œ Featured Projects

### ğŸš€ Coinbase Crypto Market Streaming Pipeline
- Real-time ingestion of live cryptocurrency prices from the Coinbase WebSocket API  
- Event streaming with **Apache Kafka (Confluent Cloud)**  
- Stream processing using **Flink SQL** with Avro schema validation  
- Time-series storage in **TimescaleDB (PostgreSQL)**  
- Sub-second latency dashboards built with **Grafana**

ğŸ‘‰ Repository: *([link here](https://github.com/ayalasher/Coinbase-realtime-market-pipeline))*

---

### ğŸï¸ Formula One Batch ETL Pipeline
- Batch ingestion of weekly Formula One race data from a public API  
- Data cleaning and transformation using **Python & Pandas**  
- Workflow orchestration and scheduling with **Apache Airflow**  
- Analytical storage in **PostgreSQL** and visualization in **Grafana**  
- Fully containerized using **Docker**

ğŸ‘‰ Repository: *([link here](https://github.com/ayalasher/F1-batch-pipeline))*
  <!-- 
---

## ğŸ—ï¸ Data Engineering Interests
- Real-time vs batch data processing architectures(Looking at your data situation before making a decision on which path to take)
- Event-driven systems and streaming platforms
- Data reliability, schema evolution, and data quality
- Observability for data pipelines (metrics, latency, failures)
- Designing analytics-ready data models


---


## ğŸ“š Currently Focusing On
- Designing scalable **data architectures**
- Advanced **Apache Kafka** patterns (partitioning, consumer groups)
- Improving **data modeling** for analytics and time-series workloads
- Building production-ready **Airflow DAGs**
- Cloud-native data pipelines on **AWS and Azure**

-->

---

## ğŸ“« Connect With Me
- ğŸ“§ Email: **maxwelayal956@gmail.com**  
- ğŸ’¼ LinkedIn: *([Link here](https://www.linkedin.com/in/maxwel-ayal-12395b2b0/))*  
- ğŸŒ Portfolio: **https://www.maxwel-ayal.tech**

---

âš¡ *Currenlty Open to data engineering roles ğŸš€*


<!---
ayalasher/ayalasher is a âœ¨ special âœ¨ repository because its `README.md` (this file) appears on your GitHub profile.
You can click the Preview link to take a look at your changes.
--->
